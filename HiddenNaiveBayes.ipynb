{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Segb7EioVVh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "df=pd.read_csv('heart_disease.csv')\n",
        "class HiddenNaiveBayesHeartDisease:\n",
        "    def _init_(self, num_classes, num_hidden_states, num_features):\n",
        "        self.num_classes = num_classes\n",
        "        self.num_hidden_states = num_hidden_states\n",
        "        self.num_features = num_features\n",
        "        self.class_probs = np.zeros(num_classes)\n",
        "        self.transition_probs = np.zeros((num_classes, num_hidden_states, num_hidden_states))\n",
        "        self.observation_probs = {i: {col: 0 for col in df.columns[2:]} for i in range(num_classes)}\n",
        "\n",
        "    def train(self, data, labels):\n",
        "        data_train, data_test, labels_train, labels_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "        # Implement training logic to estimate parameters\n",
        "        for label in range(self.num_classes):\n",
        "            # Filter data for the current class\n",
        "            class_data = data_train[labels_train == label]\n",
        "\n",
        "            # Estimate class probabilities\n",
        "            self.class_probs[label] = len(class_data) / len(data_train)\n",
        "\n",
        "            # Estimate transition probabilities\n",
        "            for i in range(self.num_hidden_states):\n",
        "                for j in range(self.num_hidden_states):\n",
        "                    # Use pandas boolean indexing to filter data\n",
        "                    count_i_j = len(class_data[(class_data.iloc[:, 0] == i) & (class_data.iloc[:, 1] == j)])\n",
        "                    total_count_i = len(class_data[class_data.iloc[:, 0] == i])\n",
        "\n",
        "                    # Avoid division by zero\n",
        "                    if total_count_i == 0:\n",
        "                        self.transition_probs[label, i, j] = 0\n",
        "                    else:\n",
        "                        self.transition_probs[label, i, j] = count_i_j / total_count_i\n",
        "\n",
        "            # Estimate observation probabilities\n",
        "            for i in range(self.num_hidden_states):\n",
        "                for col_name in data.columns[2:]:\n",
        "                    self.observation_probs[label][col_name] = np.mean(class_data[class_data.iloc[:, 0] == i][col_name])\n",
        "\n",
        "    def predict(self, features):\n",
        "\n",
        "        # Implement inference logic to predict class labels\n",
        "        predictions = []\n",
        "        for instance_features in features:\n",
        "            instance_probs = []\n",
        "            for label in range(self.num_classes):\n",
        "                class_prob = np.log(self.class_probs[label])\n",
        "                transition_prob = 0\n",
        "                observation_prob = 0\n",
        "                for i in range(self.num_hidden_states):\n",
        "                    # Handle the case where the feature value is a string (e.g., 'A')\n",
        "                    try:\n",
        "                        feature_value = instance_features[i]\n",
        "                        # Assuming you have the test data as a list of lists\n",
        "                        transition_prob += np.log(self.transition_probs[label, int(feature_value), i])\n",
        "                        for col_name in data.columns[2:]:\n",
        "                            observation_prob += np.log(np.random.normal(self.observation_probs[label][col_name], 1e-3))\n",
        "                    except (ValueError, IndexError):\n",
        "                        # Handle the conversion to int or index error (if the feature value is not an integer)\n",
        "                        transition_prob += 0\n",
        "\n",
        "                instance_probs.append(class_prob + transition_prob + observation_prob)\n",
        "            predictions.append(np.argmax(instance_probs))\n",
        "        return np.array(predictions)\n",
        "\n",
        "# Example usage:\n",
        "# Assuming you have heart disease data (heart_data) and corresponding labels (heart_labels)\n",
        "num_classes = 2\n",
        "num_hidden_states = 3\n",
        "num_features = 20  # Adjust this based on your heart disease dataset features\n",
        "\n",
        "heart_nb_model = HiddenNaiveBayesHeartDisease(num_classes, num_hidden_states, num_features)\n",
        "target='Heart Attack Risk'\n",
        "heart_data=df.drop(target,axis=1)\n",
        "heart_labels=df[target]\n",
        "# Assuming you have training data (heart_data) and corresponding labels (heart_labels)\n",
        "heart_nb_model.train(heart_data, heart_labels)\n",
        "test_heart_data=df.iloc[:100]\n",
        "test_heart_features=test_heart_data.values.tolist()\n",
        "# Assuming you have test features (test_heart_features)\n",
        "predicted_labels = heart_nb_model.predict(test_heart_features)\n",
        "true_labels=test_heart_data[target].values\n",
        "# Evaluate the model, e.g., using accuracy\n",
        "accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    }
  ]
}